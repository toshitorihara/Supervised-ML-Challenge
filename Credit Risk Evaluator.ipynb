{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Retrieval"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\r\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing: Convert categorical data to numeric"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\r\n",
    "dummies_2019 = pd.get_dummies(train_df)\r\n",
    "dummies_2019.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(12180, 96)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\r\n",
    "dummies_2020 = pd.get_dummies(test_df)\r\n",
    "dummies_2020.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4702, 95)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# add missing dummy variables to testing set\r\n",
    "for column in dummies_2019.columns:\r\n",
    "    if (not column in dummies_2020.columns):\r\n",
    "        print(column)  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "debt_settlement_flag_Y\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "dummies_2019.loc[dummies_2019['debt_settlement_flag_Y'] == 1, ['debt_settlement_flag_N', 'debt_settlement_flag_Y']]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debt_settlement_flag_N</th>\n",
       "      <th>debt_settlement_flag_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6896</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6930</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7243</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9018</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      debt_settlement_flag_N  debt_settlement_flag_Y\n",
       "6896                       0                       1\n",
       "6930                       0                       1\n",
       "7243                       0                       1\n",
       "7730                       0                       1\n",
       "9018                       0                       1"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def cleaning (row):\r\n",
    "   if row['debt_settlement_flag_N'] == 1 :\r\n",
    "      return 0\r\n",
    "   if row['debt_settlement_flag_N'] == 0 :\r\n",
    "        return 1\r\n",
    "dummies_2020['debt_settlement_flag_Y'] = dummies_2020.apply (lambda row: cleaning(row), axis=1)\r\n",
    "dummies_2020.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4702, 96)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X_train1 = dummies_2019.drop(columns='loan_status_high_risk', axis=1)\r\n",
    "X_train = X_train1.drop(columns='loan_status_low_risk', axis=1) \r\n",
    "y_train = dummies_2019['loan_status_low_risk']\r\n",
    "X_test1 = dummies_2020.drop(columns='loan_status_high_risk', axis=1)\r\n",
    "X_test = X_test1.drop(columns='loan_status_low_risk', axis=1) \r\n",
    "y_test = dummies_2020['loan_status_low_risk']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Consider the models: Prediction and comparison\r\n",
    "Prediction: Random Forest Classifier would perform better as it has more categorial data than numeric which is typically not suitable for Logistic Regression."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "LR = LogisticRegression().fit(X_train , y_train)\r\n",
    "\r\n",
    "print(f'Training Score: {LR.score(X_train , y_train)}')\r\n",
    "print(f'Test Score: {LR.score(X_test , y_test)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Score: 0.6485221674876848\n",
      "Test Score: 0.5253083794130158\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\h-torihara\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Train a Random Forest Classifier model on the unscaled data and print the model score\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "RF = RandomForestClassifier().fit(X_train , y_train)\r\n",
    "\r\n",
    "print(f'Training Score: {RF.score(X_train , y_train)}')\r\n",
    "print(f'Test Score: {RF.score(X_test , y_test)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Score: 1.0\n",
      "Test Score: 0.6256911952360698\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Interim Result\r\n",
    "The result of the \"unscaled\" data turned out as following:\r\n",
    "* Logistic Regression: Training Score: 0.64 / Test Score: 0.52\r\n",
    "* Random Forest Classifier: Training Score: 1.0 / Test Score: 0.60 <p>\r\n",
    "\r\n",
    "It seems the Random Forest Classifier performed better than Logistic Regression for the unscaled data, but the training score of 1.0 may be indicating that there is overfitting. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Revisit the Preprocessing: Scale the data\r\n",
    "Prediction: Scaling would have positive impact to improve accuracy of the gradient descent algorithm such as Logistic Regression while tree-based algorithms such as Random Forest Classifier do not."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Scaling the training data\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler = StandardScaler().fit(X_train)\r\n",
    "\r\n",
    "X_train_scaled = scaler.transform(X_train)\r\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Fitting the models to the scaled data\r\n",
    "\r\n",
    "# Logistic Regression\r\n",
    "LRS = LogisticRegression().fit(X_train_scaled , y_train)\r\n",
    "print(f'Logistic Regression Scaled Score: {LRS.score(X_test_scaled , y_test)}')\r\n",
    "\r\n",
    "# Random Forest Classifier\r\n",
    "RFS = RandomForestClassifier().fit(X_train_scaled , y_train)\r\n",
    "print(f'Random Forest Classifier Score: {RFS.score(X_test_scaled , y_test)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\h-torihara\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic Regression Scaled Score: 0.7201190982560612\n",
      "Random Forest Classifier Score: 0.6397277754147171\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\r\n",
    "The result of the \"scaled\" data turned out as following:\r\n",
    "* Logistic Regression Score: Scaled: 0.72 (Unscaled: 0.52)\r\n",
    "* Random Forest Classifier Score: Scales: 0.63 (Unscaled: 0.60)<p>\r\n",
    "\r\n",
    "It turned out the Logistic Regression (despite its less compute intensive or complicated algorithm) ended up outperforming the Random Forest Classifier as predicted above. It seems the scaling takes a dominant part of Logistic Regression which improved the result of unscaled data by 38%. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "interpreter": {
   "hash": "352eb0fdbc39df23c3941759226aac7a80e9e8fcb0968112f6f9929c3d7daf2e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}